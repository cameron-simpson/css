#!/bin/sh
#
# Import a static website into an Amazon AWS S3 bucket for static serving.
#   - Cameron Simpson <cs@zip.com.au> 05dec2015
#

set -ue

: ${S3CFG:=$HOME/.s3cfg-$AWS_ID}

no_wget=
no_sync=
no_fixmime=
htdocs_dir=
ht_userarea=

cmd=$( basename "$0" )
usage="Usage: $cmd [--no-wget] [--no-sync] [-d htdocs-dir] fqdn s3-bucket-name
  --no-fixmime  Do not update the MIME types of problem extensions.
  --no-sync     Do not update the S3 bucket from the htdocs tree.
  --no-wget     Do not update the htdocs tree from the source website.
  --password username:areaname
                Read password for username from .password-areaname.
  -d htdocs-dir
            Use the specified directory as the htdocs tree; the default is
            taken from the FQDN."

badopts=

while [ $# -gt 0 ]
do
  case "$1" in
    --no-fixmime)   no_fixmime=1 ;;
    --no-sync)      no_sync=1 ;;
    --no-wget)      no_wget=1 ;;
    --password)     ht_userarea=$2; shift ;;
    -d)             htdocs_dir=$2; shift ;;
    --)             shift; break ;;
    -?*)            echo "$cmd: unrecognised option: $1" >&2
                    badopts=1
                    ;;
    *)              break ;;
  esac
  shift
done

# sanity check ht credentials
if [ -n "$ht_userarea" ]
then
    case "$ht_userarea" in
      ?*:?*)
        ht_username=$( expr "x$ht_userarea" : 'x\([^:]*\):.*' )
        ht_areaname=$( expr "x$ht_userarea" : 'x[^:]*:\(.*\)' )
        ht_password_file=$HOME/.htpassword-$ht_areaname
        if [ ! -s "$ht_password_file" ]
        then
          echo "$cmd: missing credentials file: $ht_password_file" >&2
          badopts=1
        else
          ht_password=$(<$ht_password_file)
        fi
        ;;
      *)echo "$cmd: invalid arguments to --password, expected \"username:areaname\"" >*2
        badopts=1
        ;;
    esac
else
  ht_username=
fi

if [ $# = 0 ]
then  echo "$cmd: missing fqdn" >&2
      badopts=1
else  fqdn=$1
      shift
fi

if [ $# = 0 ]
then  echo "$cmd: missing s3-bucket-name" >&2
      badopts=1
else  s3bucket=$1
      shift
fi

if [ $# -gt 0 ]
then
  echo "$cmd: extra arguments after s3-bucket-name: $*" >&2
  badopts=1
fi

[ $badopts ] && { echo "$usage" >&2; exit 2; }

srcurl=http://$fqdn/
dsturl=s3://$s3bucket
[ -n "$htdocs_dir" ] || htdocs_dir=$fqdn

s3(){
  s3cmd -q -c "$S3CFG" ${1+"$@"}
}

setx(){
  ( set -x; "$@" )
}

xit=0

cd "$htdocs_dir"

if [ -z "$no_wget" ]
then
  set -- wget -q -mp -nH
  recite=$*
  if [ -n "$ht_username" ]
  then
    set -- "$@" "--user=$ht_username" "--password=$ht_password"
    recite="$recite --user=$ht_username --password=******"
  fi
  echo "$recite $srcurl" >&2
  "$@" "$srcurl" \
  || echo "$cmd: warning: wget had errors, rerun with -nv for details" >&2
fi

[ $no_sync ] || setx s3 -MP sync . "$dsturl"

if [ -z "$no_fixmime" ]
then
  # repair MIME types for various extensions
  for fixext in text/css:.css video/x-f4v:.f4v application/rdf+xml:.rdf audio/x-ms-wma:.wma video/quicktime:.mov
  do
    mimetype=$( expr "x$fixext" : 'x\(.*\):.*' )
    suffix=$(   expr "x$fixext" : 'x.*:\(.*\)' )
    find * -type f -iname "*$suffix" \
    | while read -r fixfile
      do
        setx s3 -P -m "$mimetype" modify "$dsturl/$fixfile"
      done
  done
fi

exit $xit
