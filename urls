#!/usr/bin/perl
#
# Extract URLs from HTML on stdin.
#	- Cameron Simpson <cs@zip.com.au> 24aug2000
#

use strict vars;

use cs::Misc;
use cs::Source;
use cs::URL;
use cs::HTML;
use cs::HTTP;
use Getopt::Std;

$::Usage="Usage: $::cmd [-itxR] [baseURL] < html
	-A	Trim anchors from URLs.
	-i	Get inline URLs (SRCs) instead of HREFs.
	-t	Print URLs title text after each URL.
	-x	Hexify the URLs.
	-R	Raw listing - list every URL mention in native order
		instead of a sorted unique list of URLs.
";

my $noanchors=0;
my $inline=0;
my $titles=0;
my $hexify=0;
my $rawlist=0;
my $base;

my $badopts=0;

getopts("AitxR") || ($badopts=1);
$noanchors=1 if defined $::opt_A;
$inline=1 if defined $::opt_i;
$titles=1 if defined $::opt_t;
$hexify=1 if defined $::opt_x;
$rawlist=1 if defined $::opt_R;

if (@ARGV)
{ $base=shift(@ARGV);
  my $U = new cs::URL $base;
  if (! defined $U)
  { warn "$::cmd: bad base URL: $base\n";
    $badopts=1;
  }
  else
  { $base=$U;
  }
}

if (@ARGV)
{ warn "$::cmd: extra arguments: @ARGV\n";
  $badopts=1;
}

die $::Usage if $badopts;

my $src = new cs::Source (FILE,STDIN);
my %urls;

my @urls = cs::HTML::sourceURLs(\%urls,$src,$inline,$base,$noanchors);

for my $url ($rawlist ? @urls : sort keys %urls)
{ print $hexify ? cs::HTTP::hexify($url,HTML) : $url;
  print "\t$urls{$url}" if $titles;
  print "\n";
}

exit 0;
